[train]
seed: 0
model_type: NMT
patience: 20
max_epochs: 100
eval_freq: 1000
eval_metrics: meteor,bleu,loss
eval_filters: de-bpe
checkpoint_freq: 1000
save_best_n: 3
l2_reg: 1e-5
gclip: 5
optimizer: adam
lr: 0.0004
batch_size: 32
save_path: ~/nmtpytorch_models
tensorboard_dir: ~/tensorboard_logs

[model]
att_type: mlp
enc_dim: 256
dec_dim: 256
emb_dim: 128
n_encoders: 1
n_decoders: 1
enc_type: gru
dec_type: gru
dropout_emb: 0.3
dropout_ctx: 0.5
dropout_out: 0.5
dropout_enc: 0
dropout_dec: 0
tied_emb: False
dec_init: mean_ctx
direction: en->de

[data]
train_set: {'en': 'data/multi30k/task1/bpe/train.norm.tok.lc.bpe10000.en',
            'de': 'data/multi30k/task1/bpe/train.norm.tok.lc.bpe10000.de',
            'fr': 'data/multi30k/task1/bpe/train.norm.tok.lc.bpe10000.fr'}
val_set: {'en': 'data/multi30k/task1/bpe/val.norm.tok.lc.bpe10000.en',
          'de': 'data/multi30k/task1/bpe/val.norm.tok.lc.bpe10000.de',
          'fr': 'data/multi30k/task1/bpe/val.norm.tok.lc.bpe10000.fr'}
test2016_set: {'en': 'data/multi30k/task1/bpe/test2016.norm.tok.lc.bpe10000.en',
               'de': 'data/multi30k/task1/bpe/test2016.norm.tok.lc.bpe10000.de',
               'fr': 'data/multi30k/task1/bpe/test2016.norm.tok.lc.bpe10000.fr'}
test2017_set: {'en': 'data/multi30k/task1/bpe/test2017.norm.tok.lc.bpe10000.en',
               'de': 'data/multi30k/task1/bpe/test2017.norm.tok.lc.bpe10000.de',
               'fr': 'data/multi30k/task1/bpe/test2017.norm.tok.lc.bpe10000.fr'}

[vocabulary]
en: data/multi30k/task1/bpe/train.norm.tok.lc.bpe10000.vocab.en
de: data/multi30k/task1/bpe/train.norm.tok.lc.bpe10000.vocab.de
